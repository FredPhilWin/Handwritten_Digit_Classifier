{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Handwritten_Digit_Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oCg3uB0u8Hx"
      },
      "source": [
        "# Handwritten Digit Classification with PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMxhVbmwu8H1"
      },
      "source": [
        "In this notebook, I will be implementing and comparing different Neural Network architectures to perform handrwritten digit classification on the MNIST dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24PVkzFZu8H2"
      },
      "source": [
        "## Install required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTpUlWyTu8H2",
        "outputId": "8cb8e0a8-d000-46cc-f631-a5ef9d7cf93e"
      },
      "source": [
        "!pip3 install numpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAehxN1eu8H4",
        "outputId": "2771d417-f034-4e80-e691-884bd97e6665"
      },
      "source": [
        "!pip3 install torch torchvision"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.10.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0FjtULOu8H4",
        "outputId": "f96a36db-864c-4ad0-efe2-474f0c0a5344"
      },
      "source": [
        "!pip3 install matplotlib"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wi3aoqu0u8H5",
        "outputId": "a730d68e-b3aa-4b61-ff6a-e5cfed48ee73"
      },
      "source": [
        "!pip3 install torch-summary"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch-summary in /usr/local/lib/python3.7/dist-packages (1.4.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyczZn42u8H6"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXzKXXbou8H6"
      },
      "source": [
        "## Download and Prepare the Dataset ðŸ“¦"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGmsn12CdKsi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzwLOsXuvMoQ"
      },
      "source": [
        "from torchvision import transforms as T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LR9o1o8-u8H7"
      },
      "source": [
        "transform = T.Compose([\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(0.5, 0.5)\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGQkFU0Au8H8",
        "outputId": "2fbaab4e-639a-4ab7-9b52-8ce6fd52c094"
      },
      "source": [
        "from torchvision import datasets\n",
        "\n",
        "trainset = datasets.MNIST(\"MNIST_data/\", download=True, train=True, transform=transform)\n",
        "testset = datasets.MNIST(\"MNIST_data/\", download=True, train=False, transform=transform)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYJ3DqHZw8Sj"
      },
      "source": [
        "Print the size of the train and testsets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "as47DgUOu8H8",
        "outputId": "35a5224c-5e0f-407d-f12d-03f9e96c00b1"
      },
      "source": [
        "print(f\"Size of trainset: {len(trainset)}\")\n",
        "print(f\"Size of testset:  {len(testset)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of trainset: 60000\n",
            "Size of testset:  10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nl4eKCKxCSt"
      },
      "source": [
        "Print an exemplary image from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "V6LwMkniu8H9",
        "outputId": "f3ce4e34-ecd3-4ac7-f43b-42683876caf4"
      },
      "source": [
        "image, label = trainset[0]\n",
        "plt.imshow(image.squeeze(),cmap=\"gray\")\n",
        "plt.title(label);\n",
        "print(image.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3kWtha0u8H9"
      },
      "source": [
        "## Create Data Loaders ðŸ’¾"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzjBBi6zu8H-"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M68XbqVAu8H-"
      },
      "source": [
        "val_share = 0.2\n",
        "n_train = len(trainset)\n",
        "split = int(val_share*n_train)\n",
        "\n",
        "indices = list(range(n_train))\n",
        "np.random.shuffle(indices)\n",
        "train_indices, val_indices = indices[split:], indices[:split]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAIoJxKEu8H-"
      },
      "source": [
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "val_sampler = SubsetRandomSampler(val_indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBdTuGKwu8H-"
      },
      "source": [
        "train_loader = DataLoader(trainset, batch_size=64, sampler=train_sampler)\n",
        "val_loader = DataLoader(trainset, batch_size=64, sampler=val_sampler)\n",
        "test_loader = DataLoader(testset, batch_size=64, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlptdlD6u8H_"
      },
      "source": [
        "## Create Neural Networks ðŸ§ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHf5o5ibu8H_"
      },
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6RSsL1Yu8H_"
      },
      "source": [
        "class vanilla_NN(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super (vanilla_NN,self).__init__()\n",
        "        \n",
        "        self.fc1 = nn.Linear(28*28, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "        self.dropout = nn.Dropout(p=0.25)\n",
        "        self.ReLU = nn.ReLU()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = x.view(x.shape[0], -1)\n",
        "        \n",
        "        x = self.fc1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.ReLU(x)\n",
        "        \n",
        "        x = self.fc2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.ReLU(x)\n",
        "        \n",
        "        x = self.fc3(x)\n",
        "        x = self.dropout(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxB-KRgWu8H_",
        "outputId": "e425881a-a313-4493-9424-589f17af8a32"
      },
      "source": [
        "summary(vanilla_NN(), input_size=(1,28,28));"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================================================\n",
            "Layer (type:depth-idx)                   Param #\n",
            "=================================================================\n",
            "â”œâ”€Linear: 1-1                            200,960\n",
            "â”œâ”€Linear: 1-2                            32,896\n",
            "â”œâ”€Linear: 1-3                            1,290\n",
            "â”œâ”€Dropout: 1-4                           --\n",
            "â”œâ”€ReLU: 1-5                              --\n",
            "=================================================================\n",
            "Total params: 235,146\n",
            "Trainable params: 235,146\n",
            "Non-trainable params: 0\n",
            "=================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M6KIHeiu8H_"
      },
      "source": [
        "class conv_NN(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(conv_NN,self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "        self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
        "        self.batchnorm1 = nn.BatchNorm2d(num_features=8)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(num_features=16)\n",
        "        self.ReLU = nn.ReLU()\n",
        "        self.fc = nn.Linear(16*7*7, 10)\n",
        "        \n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.batchnorm1(x)\n",
        "        x = self.ReLU(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.batchnorm2(x)\n",
        "        x = self.ReLU(x)\n",
        "        \n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.fc(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        \n",
        "        return x\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeqvGBcSu8IA",
        "outputId": "4078a26f-1fcb-4183-fa12-977008270ef4"
      },
      "source": [
        "summary(conv_NN(), input_size=(1,28,28));"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================================================\n",
            "Layer (type:depth-idx)                   Param #\n",
            "=================================================================\n",
            "â”œâ”€Conv2d: 1-1                            80\n",
            "â”œâ”€Conv2d: 1-2                            1,168\n",
            "â”œâ”€MaxPool2d: 1-3                         --\n",
            "â”œâ”€BatchNorm2d: 1-4                       16\n",
            "â”œâ”€BatchNorm2d: 1-5                       32\n",
            "â”œâ”€ReLU: 1-6                              --\n",
            "â”œâ”€Linear: 1-7                            7,850\n",
            "=================================================================\n",
            "Total params: 9,146\n",
            "Trainable params: 9,146\n",
            "Non-trainable params: 0\n",
            "=================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKY3Fl0bu8IA"
      },
      "source": [
        "## Train Models ðŸ“‰"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qE33F1J-u8IA"
      },
      "source": [
        "from torch import optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbT_1dIgu8IA"
      },
      "source": [
        "def multiclass_accuracy(y_pred, y_true):\n",
        "    top_p, top_class = y_pred.topk(1, dim=1)\n",
        "    equals = top_class == y_true.view(*top_class.shape)\n",
        "    return torch.mean(equals.type(torch.FloatTensor))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "um0B3PdVgyxd"
      },
      "source": [
        "  criterion = nn.NLLLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-u8pxh-u8IA"
      },
      "source": [
        "def train_model(model, epochs=10):\n",
        "  optimizer = optim.Adam(model.parameters(), lr=3e-3)\n",
        "  \n",
        "  for i in range(epochs):\n",
        "      train_loss = 0.0\n",
        "      val_loss = 0.0\n",
        "      val_acc = 0.0\n",
        "      \n",
        "      model.train()\n",
        "      \n",
        "      for images, labels in train_loader:\n",
        "          log_probs = model(images)\n",
        "          optimizer.zero_grad()\n",
        "          loss = criterion(log_probs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          train_loss += loss.item()\n",
        "      \n",
        "      \n",
        "      model.eval()\n",
        "      \n",
        "      for images, labels in val_loader:\n",
        "          log_probs = model(images)\n",
        "          probs = torch.exp(log_probs)\n",
        "          loss = criterion(log_probs, labels)\n",
        "          val_loss += loss.item()\n",
        "          val_acc += multiclass_accuracy(probs, labels)\n",
        "      \n",
        "      train_loss = train_loss/len(train_loader)\n",
        "      val_loss = val_loss/len(val_loader)\n",
        "      val_acc = val_acc/len(val_loader)\n",
        "      \n",
        "      print(f\"Epoch {i+1}/{epochs}: training loss: {train_loss:.2f}, validation loss: {val_loss:.2f}, validation accuracy: {val_acc*100:.2f}%\")\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kC3cJNnNd3ZB",
        "outputId": "13d81c61-5bd7-4249-8c41-4cc366c6d777"
      },
      "source": [
        "trained_conv_NN = train_model(conv_NN())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10: training loss: 0.13, validation loss: 0.06, validation accuracy: 98.17%\n",
            "Epoch 2/10: training loss: 0.05, validation loss: 0.06, validation accuracy: 98.25%\n",
            "Epoch 3/10: training loss: 0.04, validation loss: 0.06, validation accuracy: 98.38%\n",
            "Epoch 4/10: training loss: 0.03, validation loss: 0.05, validation accuracy: 98.47%\n",
            "Epoch 5/10: training loss: 0.03, validation loss: 0.05, validation accuracy: 98.52%\n",
            "Epoch 6/10: training loss: 0.02, validation loss: 0.07, validation accuracy: 98.15%\n",
            "Epoch 7/10: training loss: 0.02, validation loss: 0.05, validation accuracy: 98.62%\n",
            "Epoch 8/10: training loss: 0.02, validation loss: 0.06, validation accuracy: 98.55%\n",
            "Epoch 9/10: training loss: 0.02, validation loss: 0.05, validation accuracy: 98.57%\n",
            "Epoch 10/10: training loss: 0.02, validation loss: 0.07, validation accuracy: 98.03%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43fi43NJd8eG",
        "outputId": "0823ab89-d21e-4817-ed3f-a928226d5645"
      },
      "source": [
        "trained_vanilla_NN = train_model(vanilla_NN())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10: training loss: 0.81, validation loss: 0.28, validation accuracy: 92.14%\n",
            "Epoch 2/10: training loss: 0.63, validation loss: 0.26, validation accuracy: 92.46%\n",
            "Epoch 3/10: training loss: 0.59, validation loss: 0.20, validation accuracy: 94.69%\n",
            "Epoch 4/10: training loss: 0.57, validation loss: 0.19, validation accuracy: 94.46%\n",
            "Epoch 5/10: training loss: 0.56, validation loss: 0.18, validation accuracy: 94.92%\n",
            "Epoch 6/10: training loss: 0.55, validation loss: 0.17, validation accuracy: 95.28%\n",
            "Epoch 7/10: training loss: 0.54, validation loss: 0.20, validation accuracy: 94.56%\n",
            "Epoch 8/10: training loss: 0.53, validation loss: 0.18, validation accuracy: 95.14%\n",
            "Epoch 9/10: training loss: 0.53, validation loss: 0.17, validation accuracy: 95.53%\n",
            "Epoch 10/10: training loss: 0.53, validation loss: 0.17, validation accuracy: 95.43%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2ZN2Pmtu8IB"
      },
      "source": [
        "## Final Evaluation âœ…"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1tmmiV7u8IB"
      },
      "source": [
        "def evaluate_model(model):\n",
        "  model.eval()\n",
        "\n",
        "  test_loss = 0.0\n",
        "  test_acc = 0.0\n",
        "\n",
        "  for images, labels in test_loader:\n",
        "      log_probs = model(images)\n",
        "      probs = torch.exp(log_probs)\n",
        "      loss = criterion(log_probs, labels)\n",
        "      test_loss += loss.item()\n",
        "      test_acc += multiclass_accuracy(probs, labels)\n",
        "\n",
        "  test_loss = test_loss/len(test_loader)\n",
        "  test_acc = test_acc/len(test_loader)\n",
        "\n",
        "  print(f\"test loss: {test_loss:.2f}, test accuracy: {test_acc*100:.2f}%\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vORtpEthgkTT",
        "outputId": "35c01287-7eb3-487d-d227-53303dc2e75c"
      },
      "source": [
        "print(\"Final Evaluation - Fully Connected Neural Network:\")\n",
        "evaluate_model(trained_vanilla_NN)\n",
        "\n",
        "print(\"Final Evaluation - Convolutional Neural Network:\")\n",
        "evaluate_model(trained_conv_NN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Evaluation - Fully Connected Neural Network:\n",
            "test loss: 0.15, test accuracy: 95.60%\n",
            "\n",
            "Final Evaluation - Convolutional Neural Network:\n",
            "test loss: 0.06, test accuracy: 98.36%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLrxwy4JloRj"
      },
      "source": [
        "As can be seen from these results, the Convolutional Neural Network (CNN) outperforms the fully connected (vanilla) Neural Network, despite the significatnly smaller number of parameters (235,146 vs. 9,146, respectively).\n",
        "\n",
        "In addition, it is noticeable that the small number of the CNN leads to tremendously reduced training time, as it already reaches above 98% accuracy after the first epoch and pretty much stays there all the way through. The Fully Connected Neural Network on the other hand converges to its maximum of around 95% only around the 6th to 7th epoch.\n",
        "\n",
        "This nicely highlghts the advantages of Convolutional Neural Networks for the analysis of structured 2D-data like, for example, images of handwritten digits."
      ]
    }
  ]
}